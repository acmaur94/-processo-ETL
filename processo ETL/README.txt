# Projeto de ETL: Importa√ß√£o de Dados do Titanic (CSV) para MySQL

Este projeto foi desenvolvido como parte de uma avalia√ß√£o para demonstrar um processo completo de **ETL (Extra√ß√£o, Transforma√ß√£o e Carga)**. O script Python realiza a extra√ß√£o de dados de arquivos CSV, neste caso, o famoso dataset do Titanic, e os carrega em um banco de dados MySQL.

## üìú Descri√ß√£o do Processo

O fluxo de ETL implementado funciona da seguinte maneira:

1.  **Extra√ß√£o (Extract):** O script l√™ todos os arquivos com a extens√£o `.csv` localizados na pasta `/data`.
2.  **Transforma√ß√£o (Transform):** Utilizando a biblioteca `pandas`, os dados do CSV s√£o carregados em um DataFrame. Embora este projeto n√£o realize transforma√ß√µes complexas, esta √© a etapa onde limpezas, convers√µes de tipo ou enriquecimento de dados poderiam ser adicionados.
3.  **Carga (Load):** Os dados do DataFrame s√£o inseridos, linha por linha, em uma tabela espec√≠fica (`dados_titanic`) no banco de dados MySQL.

## Dataset Utilizado

O conjunto de dados utilizado para este exemplo √© o **"Titanic: Machine Learning from Disaster"**, dispon√≠vel no Kaggle. Ele cont√©m informa√ß√µes demogr√°ficas e de viagem dos passageiros do RMS Titanic.

-   **Fonte:** [Kaggle Titanic Dataset](https://www.kaggle.com/c/titanic/data)
-   **Arquivo Exemplo:** `titanic.csv` (deve ser colocado na pasta `/data`)

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.x
* **Bibliotecas:**
    * `pandas`
    * `mysql-connector-python`
* **Banco de Dados:** MySQL Server

## üìÇ Estrutura do Projeto

O projeto est√° organizado da seguinte forma para manter a clareza e separa√ß√£o de responsabilidades: